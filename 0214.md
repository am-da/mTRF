
biosemi 32 map
<img width="400" alt="スクリーンショット 2024-02-13 15 12 50" src="https://github.com/am-da/mTRF/assets/112613519/be1350ab-e58a-4ed4-b02f-c6484823bbee">



40 movies - 17 features

<img width="1204" alt="スクリーンショット 2024-02-14 8 37 46" src="https://github.com/am-da/mTRF/assets/112613519/a9ab0b0e-abe5-41cb-b60d-26d75430aa0f">

<img width="1229" alt="スクリーンショット 2024-02-14 8 38 54" src="https://github.com/am-da/mTRF/assets/112613519/3726ed14-49e6-4b97-8dc3-49c496faa0ad">
<img width="1210" alt="スクリーンショット 2024-02-14 8 39 07" src="https://github.com/am-da/mTRF/assets/112613519/548fac6b-8ed0-4e5a-b0d1-c696ba478284">
<img width="1209" alt="スクリーンショット 2024-02-14 8 39 21" src="https://github.com/am-da/mTRF/assets/112613519/0235639d-67ef-44fc-9ab6-26df4f9993f3">
<img width="1217" alt="スクリーンショット 2024-02-14 8 39 33" src="https://github.com/am-da/mTRF/assets/112613519/03024b53-e4e6-43b7-8f01-015c63120df0">
<img width="1217" alt="スクリーンショット 2024-02-14 8 39 44" src="https://github.com/am-da/mTRF/assets/112613519/bf913d49-ed50-4855-a920-7d5ff76fbae9![Uploading スクリーンショット 2024-02-14 8.39.55.png…]()">
<img width="1208" alt="スクリーンショット 2024-02-14 8 40 13" src="https://github.com/am-da/mTRF/assets/112613519/9660e2d3-e59f-422d-a5bf-739c4e04fedd">
<img width="1200" alt="スクリーンショット 2024-02-14 8 40 25" src="https://github.com/am-da/mTRF/assets/112613519/6a996890-a5cc-4d07-a0a9-2c35b8ce38eb">


<details><summary>code</summary>

```python
# グラフ出力成功1
import numpy as np
import matplotlib.pyplot as plt
from scipy.io import loadmat
from os.path import join
import mne

from mne.decoding import ReceptiveField
from sklearn.model_selection import KFold
from sklearn.preprocessing import scale
import pandas as pd

# エクセルファイルからstart_timeを読み込む
start_times_df = f"/Users/ami/Desktop/UCSD/time_list.csv"
start_times = pd.read_csv(start_times_df)
# データの番号のリスト (被験者数22人)
subject_numbers = range(1, 23) 
# 変更！
# 動画の番号 (1~40)
movie_numbers =  range(11, 15)
feature_numbers = range(1, 18)

for movie_number in movie_numbers:
    for feature_number in feature_numbers:
        all_raw_data = np.zeros((32, 1921)) # 全ての被験者のデータを格納するための空の配列を作成
        all_face_data = np.zeros(1500) # 全ての被験者の顔データを格納するための空の配列を作成
        for subject_number in subject_numbers:
            print(start_times.iloc[movie_number, subject_number])
            start_time = start_times.iloc[movie_number, subject_number] #[movie, subject] (movie number-1を記入)
            eeg_path = f"/Users/ami/Desktop/UCSD/prepro_{subject_number:02d}.fif"
            face_path = f"/Users/ami/Desktop/UCSD/result_mix/{subject_number}/out_extract_{subject_number:02d}/extracted_data{subject_number:02d}_{movie_number:02d}.csv"
            raw = mne.io.read_raw_fif(eeg_path, preload=True)
            sfreq = raw.info['sfreq']  # サンプリング周波数を取得
            n_channels = len(raw.ch_names)  # チャンネル数を取得
            decim = 2  # (任意の変数)
            sfreq /= decim
            face_data = pd.read_csv(face_path)
            face = face_data.iloc[:, feature_number].values #(1から17)
            face = mne.filter.resample(face.astype(float), down=decim, npad="auto")
            raw = raw.copy().resample(sfreq / decim)  # RawArrayをコピーしてリサンプル
            end_time = start_time + 60
            raw.crop(tmin=start_time, tmax=end_time)  # 指定した時間帯のデータを抽出
            info = mne.create_info(raw.ch_names, sfreq, "eeg")
            data = raw.get_data()  # EEGデータを取得
            all_raw_data += data
            all_face_data += face

        average_raw_data = all_raw_data / 22
        average_face_data = all_face_data / 22
        raw = mne.io.RawArray(average_raw_data, info)  # データとinfoを合わせて新しいRawArrayを作成
        face = average_face_data

        tmin, tmax = -0.5, 0.5
        rf = ReceptiveField(tmin, tmax, sfreq, feature_names=["envelope"], estimator=1.0, scoring="corrcoef")
        n_delays = int((tmax - tmin) * sfreq) + 2
        # 交差検証のための分割数を設定し、KFoldクラスを初期化
        n_splits = 3
        cv = KFold(n_splits)

        # モデルようにデータを準備。faceデータを転置し、モデルの出力データ(EEG)Yを取得。
        face = face.T
        Y, _ = raw[:] 
        Y = Y.T

        # 特徴量とEEGの間の線形関係を評価するために、モデルを学習させる
        # スプリットごとにモデルを適合させ、予測/テストを繰り返す
        coefs = np.zeros((n_splits, n_channels, n_delays))
        scores = np.zeros((n_splits, n_channels))
        for ii, (train, test) in enumerate(cv.split(face)):
            print("split %s / %s" % (ii + 1, n_splits))
            X_train = face[train][:, np.newaxis]  # n_featuresのために新しい軸を追加
            # モデルを適合
            rf.fit(X_train, Y[train])
            # 同じ形状のテストデータを準備
            X_test = face[test][:, np.newaxis]
            # スコアと係数を計算
            scores[ii] = rf.score(X_test, Y[test])
            coefs2 = np.zeros((n_splits, n_channels, n_delays-1))
            coefs2[ii] = rf.coef_[:, 0, :]

        mean_scores = scores.mean(axis=0)
        times = np.linspace(tmin, tmax, n_delays-1)
        # times = np.arange(n_delays) * (1.0 / sfreq)
        # 交差検証スプリットごとのスコアと係数を平均化 coefは係数、scoreは相関係数
        mean_coefs = coefs2.mean(axis=0)
        mean_scores = scores.mean(axis=0)

        # 各遅延時間に対する処理を行います
        positive_sums = []
        positive_counts = []
        # mean_coefs のデータを元に処理を行います
        # mean_coefs が 32x65 の2次元配列として与えられていると仮定します
        # 各遅延時間に対してループを行います
        for i in range(mean_coefs.shape[1]):
            # 各遅延時間における正の値のみを抽出して合計します
            positive_sum = np.sum(mean_coefs[:, i][mean_coefs[:, i] > 0])
            positive_sums.append(positive_sum)
            # 各遅延時間における正の値の個数を数えます
            positive_count = np.sum(mean_coefs[:, i] > 0)
            positive_counts.append(positive_count)
        # 正の値の平均を計算します
        positive_means = [positive_sum / positive_count if positive_count > 0 else 0 for positive_sum, positive_count in zip(positive_sums, positive_counts)]
        # 最も正の平均値が大きい遅延時間を見つけます
        max_positive_mean_index = np.argmax(positive_means)
        max_positive_mean_delay = times[max_positive_mean_index]
        # 結果を出力します
        print("Delay time with maximum positive mean:", max_positive_mean_delay)

        # 平均予測スコアをプロット
        fig, ax = plt.subplots()
        ix_chs = np.arange(n_channels)
        ax.plot(ix_chs, mean_scores)
        ax.axhline(0, ls="--", color="r")
        ax.set(title="Mean prediction score", xlabel="Channel", ylabel="Score ($r$)")
        time_plot = max_positive_mean_delay  # For highlighting a specific time.
        fig, ax = plt.subplots(figsize=(4, 8))
        max_coef = mean_coefs.max()

        ax.pcolormesh(
            times,
            ix_chs,
            mean_coefs,
            cmap="RdBu_r",
            vmin=-max_coef,
            vmax=max_coef,
            shading="gouraud",
        )

        ax.axvline(time_plot, ls="--", color="k", lw=2)
        ax.set(
            xlabel="Delay (s)",
            ylabel="Channel",
            title="Mean Model\nCoefficients",
            xlim=times[[0, -1]],
            ylim=[len(ix_chs) - 1, 0],
            xticks=np.arange(tmin, tmax + 0.2, 0.2),
        )

        plt.setp(ax.get_xticklabels(), rotation=45)
        plt.tight_layout() 
        plt.savefig(f"/Users/ami/Desktop/UCSD/graph_0214/heatmap_{movie_number}_{feature_number}.png")
        # 'times' 配列内で 'time_plot' に最も近い時間を探し、そのインデックスを 'ix_plot' に格納します。
        ix_plot = np.argmin(np.abs(time_plot - times))
        fig, ax = plt.subplots()

        # "biosemi32" テンプレートを使用して Montage オブジェクト 'easycap_montage' を作成
        easycap_montage = mne.channels.make_standard_montage("biosemi32")
        # チャンネル名、サンプリング周波数、チャンネルタイプを指定して空の 'info' オブジェクトを作成
        info = mne.create_info(ch_names=easycap_montage.ch_names, sfreq=1000.0, ch_types='eeg')
        info.set_montage(easycap_montage)
        mne.viz.plot_topomap(mean_coefs[:, ix_plot], pos=info, axes=ax, show=False, vlim=(-max_coef, max_coef))
        ax.set(title="Topomap of model coefficients\nfor delay %s" % time_plot)
        plt.tight_layout() 
        plt.savefig(f"/Users/ami/Desktop/UCSD/graph_0214/topomap_{movie_number}_{feature_number}.png")



```


</details>

