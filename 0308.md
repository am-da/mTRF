
## 修正前

### subject 2について

計測のエラー等ではなかった　　

表情特徴量がほとんどない　→  正確なmapが作られていない？　　

なぜshannel 32 だけが赤くなるのかはわからない　　

<details><summary>グラフ</summary>
   
 <br> 
 
movie 14 - feature - subject 2  　　

<img width="900" alt="スクリーンショット 2024-03-05 10 18 33" src="https://github.com/am-da/mTRF/assets/112613519/e416b911-3933-40b0-97c1-fa5d6e3aec09">
<img width="800" alt="スクリーンショット 2024-03-05 10 18 22" src="https://github.com/am-da/mTRF/assets/112613519/97ee550f-6afe-49de-8291-eb1a71c9d191">  
</details>
  
 <br>  



### 正規化について

brain and stimulus activityのグラフを表示する際は正規化していたが、topomap表示の際は正規化を行なっていなかった。

<details><summary>正規化グラフ</summary>
<img width="855" alt="スクリーンショット 2024-03-05 10 32 44" src="https://github.com/am-da/mTRF/assets/112613519/8750cfe7-4a12-491e-9747-d2bd940a331c">
</details>
  
 <br> 


### 脳波データ

<details><summary>subject 1</summary>

movie 1  
<img width="1000" alt="スクリーンショット 2024-03-05 13 37 36" src="https://github.com/am-da/mTRF/assets/112613519/e03c342c-abda-4ec1-b6ff-c4bcf727c3bf">
 <br> 

movie 3
<img width="1000" alt="スクリーンショット 2024-03-05 13 59 35" src="https://github.com/am-da/mTRF/assets/112613519/eb143e39-3435-4751-868b-5c84322cb568">
 <br> 

movie 4  
<img width="1000" alt="スクリーンショット 2024-03-05 13 43 20" src="https://github.com/am-da/mTRF/assets/112613519/e575248c-a096-4fe0-a96d-e8b5e067a23d">
<img width="1000" alt="スクリーンショット 2024-03-05 13 56 35" src="https://github.com/am-da/mTRF/assets/112613519/424818f6-5326-4647-b387-af2741b52aca">
 <br> 

movie 5  
<img width="1000" alt="スクリーンショット 2024-03-05 13 54 46" src="https://github.com/am-da/mTRF/assets/112613519/ecf810dd-48d0-47d9-8ff8-2a8972321531">
 <br> 


</details>

 <br> 



## 修正後

### 前処理

<details><summary>コード(前処理)</summary>
   
```python
import mne

data_nums = range(1, 23)

for data_num in data_nums:
    print(data_num)
    raw = mne.io.read_raw_bdf(f'/Users/ami/PycharmProjects/UCSD_pycharm/UCSD/DEAP_data/data_original/s{data_num:02d}.bdf', preload=True)
    brain_channels = list(range(0, 32))
    raw_brain = raw.copy().pick_channels([raw.ch_names[i] for i in brain_channels])
    raw_brain.filter(1, 50, fir_design='firwin')
    raw_brain.resample(128)
    raw_brain.set_eeg_reference('average', projection=True)
    raw_brain.apply_proj()
    output_path = f'/Users/ami/PycharmProjects/UCSD_pycharm/UCSD/prepro_{data_num:02d}.fif'  # 保存先のファイルパスを指定
    raw_brain.save(output_path, overwrite=True)  # ファイルを上書き保存

```
</details>

<details><summary>コード(本体)</summary>
   
```python

import numpy as np
import matplotlib.pyplot as plt
import mne
from mne.decoding import ReceptiveField
from sklearn.model_selection import KFold
import pandas as pd

start_times_df = f"/Users/ami/PycharmProjects/UCSD_pycharm/UCSD/time_list.csv"
start_times = pd.read_csv(start_times_df)

movie_numbers = range(1, 4) # 動画の番号 (1~40)
feature_numbers = range(1, 3) # 特徴量17
subject_numbers = range(1, 22) # 被験者数22人

for movie_number in movie_numbers:
    for feature_number in feature_numbers:
        all_raw_data = np.zeros((32, 7681))
        all_face_data = np.zeros(3000)
        for subject_number in subject_numbers:
            start_time = start_times.iloc[movie_number-1, subject_number] # 「注意」movienumber-1　は固定
            eeg_path = f"/Users/ami/PycharmProjects/UCSD_pycharm/UCSD/prepro_{subject_number:02d}.fif"
            face_path = f"/Users/ami/PycharmProjects/UCSD_pycharm/UCSD/result_mix/{subject_number}/out_extract_{subject_number:02d}/extracted_data{subject_number:02d}_{movie_number:02d}.csv"
            raw = mne.io.read_raw_fif(eeg_path, preload=True) #EEGデータの読み込み
            sfreq = raw.info['sfreq']  # サンプリング周波数を取得
            print("sfreq : ", sfreq)
            n_channels = len(raw.ch_names) # 変更！
            # decim = 2  # (任意の変数)
            # sfreq /= decim
            face_data = pd.read_csv(face_path) #faceデータ読み込み
            face = face_data.iloc[:, feature_number].values #指定された列のfaceデータを読み込む(1から17)
            # face = mne.filter.resample(face.astype(float), down=decim, npad="auto") #faceデータのダウンサンプリング
            # raw = raw.copy().resample(sfreq)  # RawArrayをコピーしてリサンプル
            end_time = start_time + 60
            raw.crop(tmin=start_time, tmax=end_time)  # 指定した時間帯のデータを抽出
            # info インスタンスは、MNE-Pythonで使用されるデータに関する情報を保持するためのオブジェクト
            info = mne.create_info(raw.ch_names, sfreq, "eeg") #変更 !
            data = raw.get_data()  # EEGデータを取得
            # data = data[:-1, :]  # 32チャンネル目を除外 変更　！
            print(data.shape)
            all_raw_data += data
            all_face_data += face
        average_raw_data = all_raw_data / 22
        average_face_data = all_face_data / 22
        raw = mne.io.RawArray(average_raw_data, info)  # データ(n_channels, n_times)とinfo(channel名など)を合わせて新しいRawArrayを作成
        face = average_face_data


        tmin, tmax = -0.5, 0.5 # 考慮する遅延時間の範囲を設定
        # ReceptiveField クラスのインスタンスを作成。時間遅れ脳波相関解析を実行するためのもの。
        # 与えられた時間範囲、サンプリング周波数、特徴量の名前、評価値の推定量、スコアリング方法などを指定
        rf = ReceptiveField(tmin, tmax, sfreq, feature_names=["envelope"], estimator=1.0, scoring="corrcoef")
        n_delays = int((tmax - tmin) * sfreq) + 2 # 時間遅れの数を計算
        n_splits = 3 # 交差検証のための分割数を設定し、KFoldクラスを初期化
        cv = KFold(n_splits)
        face = face.T # モデル用にデータを準備。faceデータを転置し
        Y, _ = raw[:] # モデルの出力データ(EEG)Yを取得。
        Y = Y.T

        # faceとEEGの間の線形関係を評価するために、モデルを学習させる
        # スプリットごとにモデルを適合させ、予測/テストを繰り返す
        coefs = np.zeros((n_splits, n_channels, n_delays))  # 係数：モデルが予測を行う際に各遅延がどれだけの重要性を持つか
        scores = np.zeros((n_splits, n_channels))  # 相関係数

        for ii, (train, test) in enumerate(cv.split(face)):
            print("split %s / %s" % (ii + 1, n_splits))
            print("face.shape", face[train].shape)  # faceは元々1次元
            X_train = face[train][:, np.newaxis]  # 多くの機械学習モデルが二次元の入力を想定しているため、元の配列に新しい軸を追加
            rf.fit(X_train, Y[train])
            X_test = face[test][:, np.newaxis]
            scores[ii] = rf.score(X_test, Y[test]) # スコアを保存
            coefs2 = np.zeros((n_splits, n_channels, n_delays-1))
            coefs2[ii] = rf.coef_[:, 0, :]  # モデルの係数を保存
        times = np.linspace(tmin, tmax, n_delays-1) # 遅延のタイミングを計算。np.linspace()は、指定された範囲内で等間隔の数値を生成

        # 交差検証スプリットごとのスコアと係数を平均化 coefは係数、scoreは相関係数
        mean_coefs = coefs2.mean(axis=0)
        mean_scores = scores.mean(axis=0)

        # 各遅延時間に対する処理を行う
        positive_sums = []
        positive_counts = []

        # mean_coefs のデータを元に処理を行う
        # mean_coefs が 32x65 の2次元配列として与えられていると仮定
        # 各遅延時間に対してループを行います
        for i in range(mean_coefs.shape[1]):
            # 各遅延時間における正の値のみを抽出して合計します
            positive_sum = np.sum(mean_coefs[:, i][mean_coefs[:, i] > 0])
            positive_sums.append(positive_sum)
            # 各遅延時間における正の値の個数を数えます
            positive_count = np.sum(mean_coefs[:, i] > 0)
            positive_counts.append(positive_count)
        # 正の値の平均を計算します
        positive_means = [positive_sum / positive_count if positive_count > 0 else 0 for positive_sum, positive_count in zip(positive_sums, positive_counts)]
        # 最も正の平均値が大きい遅延時間を見つけます
        max_positive_mean_index = np.argmax(positive_means)
        max_positive_mean_delay = times[max_positive_mean_index]
        #max_positive_mean_delay = 0.28
        # 結果を出力します
        print("Delay time with maximum positive mean:", max_positive_mean_delay)


        # 平均予測スコアをプロット
        #fig, ax = plt.subplots() # 新しい図と軸を作成
        ix_chs = np.arange(n_channels) # チャンネルのインデックスを作成
        #ax.plot(ix_chs, mean_scores) # 平均予測スコアをプロット
        #ax.set(title="Mean prediction score", xlabel="Channel", ylabel="Score ($r$)")


        #ヒートマップ
        time_plot = max_positive_mean_delay  # 特定の時間をハイライト
        fig, ax = plt.subplots(figsize=(4, 8)) #  新しい図と軸を作成
        max_coef = mean_coefs.max()
        # 係数のヒートマップを描画
        ax.pcolormesh(
            times,
            ix_chs,
            mean_coefs,
            cmap="RdBu_r",
            vmin=-max_coef,
            vmax=max_coef,
            shading="gouraud",
        )
        ax.axvline(time_plot, ls="--", color="k", lw=2) # 特定の時間を縦線でハイライト

        # 軸のラベルとタイトルを設定し
        ax.set(
            xlabel="Delay (s)",
            ylabel="Channel",
            title="Mean Model\nCoefficients",
            xlim=times[[0, -1]],
            ylim=[len(ix_chs) - 1, 0],
            xticks=np.arange(tmin, tmax + 0.2, 0.2),
        )

        plt.setp(ax.get_xticklabels(), rotation=45)
        plt.tight_layout()
        plt.savefig(f"/Users/ami/PycharmProjects/UCSD_pycharm/UCSD/0306/heatmap_{movie_number}_{feature_number}.png")

        # topomap
        # 'times' 配列内で 'time_plot' に最も近い時間を探し、そのインデックスを 'ix_plot' に格納
        ix_plot = np.argmin(np.abs(time_plot - times))
        fig, ax = plt.subplots() # 新しい図と軸を作成
        # "biosemi32" テンプレートを使用して Montage オブジェクト 'easycap_montage' を作成
        easycap_montage = mne.channels.make_standard_montage("biosemi32")
        # チャンネル名、サンプリング周波数、チャンネルタイプを指定して空の 'info' オブジェクトを作成
        info = mne.create_info(ch_names=easycap_montage.ch_names, sfreq=128, ch_types='eeg')  # 変更　！
        info.set_montage(easycap_montage)

        # モデル係数のトポグラフィを描画
        mne.viz.plot_topomap(mean_coefs[:, ix_plot], pos=info, axes=ax, show=False, vlim=(-max_coef, max_coef))
        ax.set(title="Topomap of model coefficients\nfor delay %s" % ix_plot)
        plt.tight_layout()
        plt.savefig(f"/Users/ami/PycharmProjects/UCSD_pycharm/UCSD/0306/topomap_{movie_number}_{feature_number}.png")

```
</details>

<details><summary>movie 5の被験者平均のmap</summary>
   
修正前　　
   
   <img width="982" alt="スクリーンショット 2024-03-05 14 38 09" src="https://github.com/am-da/mTRF/assets/112613519/d612807b-9572-4938-bc35-f7dc8aa1ccea">

 <br> 



修正後 

<img width="828" alt="スクリーンショット 2024-03-05 14 38 34" src="https://github.com/am-da/mTRF/assets/112613519/14bb18f8-bc4b-422c-956b-500a7ecf72ff">
</details>





 <br> 

## ジャンル

<details><summary>movieのジャンル</summary>
  
last fmの感情タグを反映。それ以外は空白。  

| subject | last.fm tag |
|:---:|:---:|
| 1 | fun |
| 2 | exciting |
| 3 | joy |
| 11 | happy |
| 12 | cheerful |
| 13 | love |
| 14 | happy |
| 15 | lovely |
| 16 | sentimental |
| 22 | sentimental |
| 23 | melancholy |
| 24 | sad |
| 25 | depressing |
| 26 | mellow |
| 31 | terrible |
| 32 | shock |
| 33 | hate |

</details>










