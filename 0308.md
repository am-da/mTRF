
## 修正前

### subject 2について

計測のエラー等ではなかった　　

表情特徴量がほとんどない　→  正確なmapが作られていない？　　

なぜshannel 32 だけが赤くなるのかはわからない　　

<details><summary>グラフ</summary>
   
 <br> 
 
movie 14 - feature - subject 2  　　

<img width="900" alt="スクリーンショット 2024-03-05 10 18 33" src="https://github.com/am-da/mTRF/assets/112613519/e416b911-3933-40b0-97c1-fa5d6e3aec09">
<img width="800" alt="スクリーンショット 2024-03-05 10 18 22" src="https://github.com/am-da/mTRF/assets/112613519/97ee550f-6afe-49de-8291-eb1a71c9d191">  
</details>
  
 <br>  



### 正規化について

brain and stimulus activityのグラフを表示する際は正規化していたが、topomap表示の際は正規化を行なっていなかった。

<details><summary>正規化グラフ</summary>
<img width="855" alt="スクリーンショット 2024-03-05 10 32 44" src="https://github.com/am-da/mTRF/assets/112613519/8750cfe7-4a12-491e-9747-d2bd940a331c">
</details>
  
 <br> 


 <br> 



## 修正後

### 前処理

<details><summary>コード(前処理)</summary>
   
```python
import mne

data_nums = range(1, 23)

for data_num in data_nums:
    print(data_num)
    raw = mne.io.read_raw_bdf(f'/Users/ami/PycharmProjects/UCSD_pycharm/UCSD/DEAP_data/data_original/s{data_num:02d}.bdf', preload=True)
    brain_channels = list(range(0, 32))
    raw_brain = raw.copy().pick_channels([raw.ch_names[i] for i in brain_channels])
    raw_brain.filter(1, 50, fir_design='firwin')
    raw_brain.resample(128)
    raw_brain.set_eeg_reference('average', projection=True)
    raw_brain.apply_proj()
    output_path = f'/Users/ami/PycharmProjects/UCSD_pycharm/UCSD/prepro_{data_num:02d}.fif'  # 保存先のファイルパスを指定
    raw_brain.save(output_path, overwrite=True)  # ファイルを上書き保存

```
</details>

<details><summary>コード(本体)</summary>
   
```python

import numpy as np
import matplotlib.pyplot as plt
import mne
from mne.decoding import ReceptiveField
from sklearn.model_selection import KFold
import pandas as pd

start_times_df = f"/Users/ami/PycharmProjects/UCSD_pycharm/UCSD/time_list.csv"
start_times = pd.read_csv(start_times_df)

movie_numbers = range(1, 4) # 動画の番号 (1~40)
feature_numbers = range(1, 3) # 特徴量17
subject_numbers = range(1, 22) # 被験者数22人

for movie_number in movie_numbers:
    for feature_number in feature_numbers:
        all_raw_data = np.zeros((32, 7681))
        all_face_data = np.zeros(3000)
        for subject_number in subject_numbers:
            start_time = start_times.iloc[movie_number-1, subject_number] # 「注意」movienumber-1　は固定
            eeg_path = f"/Users/ami/PycharmProjects/UCSD_pycharm/UCSD/prepro_{subject_number:02d}.fif"
            face_path = f"/Users/ami/PycharmProjects/UCSD_pycharm/UCSD/result_mix/{subject_number}/out_extract_{subject_number:02d}/extracted_data{subject_number:02d}_{movie_number:02d}.csv"
            raw = mne.io.read_raw_fif(eeg_path, preload=True) #EEGデータの読み込み
            sfreq = raw.info['sfreq']  # サンプリング周波数を取得
            print("sfreq : ", sfreq)
            n_channels = len(raw.ch_names) # 変更！
            # decim = 2  # (任意の変数)
            # sfreq /= decim
            face_data = pd.read_csv(face_path) #faceデータ読み込み
            face = face_data.iloc[:, feature_number].values #指定された列のfaceデータを読み込む(1から17)
            # face = mne.filter.resample(face.astype(float), down=decim, npad="auto") #faceデータのダウンサンプリング
            # raw = raw.copy().resample(sfreq)  # RawArrayをコピーしてリサンプル
            end_time = start_time + 60
            raw.crop(tmin=start_time, tmax=end_time)  # 指定した時間帯のデータを抽出
            # info インスタンスは、MNE-Pythonで使用されるデータに関する情報を保持するためのオブジェクト
            info = mne.create_info(raw.ch_names, sfreq, "eeg") #変更 !
            data = raw.get_data()  # EEGデータを取得
            # data = data[:-1, :]  # 32チャンネル目を除外 変更　！
            print(data.shape)
            all_raw_data += data
            all_face_data += face
        average_raw_data = all_raw_data / 22
        average_face_data = all_face_data / 22
        raw = mne.io.RawArray(average_raw_data, info)  # データ(n_channels, n_times)とinfo(channel名など)を合わせて新しいRawArrayを作成
        face = average_face_data


        tmin, tmax = -0.5, 0.5 # 考慮する遅延時間の範囲を設定
        # ReceptiveField クラスのインスタンスを作成。時間遅れ脳波相関解析を実行するためのもの。
        # 与えられた時間範囲、サンプリング周波数、特徴量の名前、評価値の推定量、スコアリング方法などを指定
        rf = ReceptiveField(tmin, tmax, sfreq, feature_names=["envelope"], estimator=1.0, scoring="corrcoef")
        n_delays = int((tmax - tmin) * sfreq) + 2 # 時間遅れの数を計算
        n_splits = 3 # 交差検証のための分割数を設定し、KFoldクラスを初期化
        cv = KFold(n_splits)
        face = face.T # モデル用にデータを準備。faceデータを転置し
        Y, _ = raw[:] # モデルの出力データ(EEG)Yを取得。
        Y = Y.T

        # faceとEEGの間の線形関係を評価するために、モデルを学習させる
        # スプリットごとにモデルを適合させ、予測/テストを繰り返す
        coefs = np.zeros((n_splits, n_channels, n_delays))  # 係数：モデルが予測を行う際に各遅延がどれだけの重要性を持つか
        scores = np.zeros((n_splits, n_channels))  # 相関係数

        for ii, (train, test) in enumerate(cv.split(face)):
            print("split %s / %s" % (ii + 1, n_splits))
            print("face.shape", face[train].shape)  # faceは元々1次元
            X_train = face[train][:, np.newaxis]  # 多くの機械学習モデルが二次元の入力を想定しているため、元の配列に新しい軸を追加
            rf.fit(X_train, Y[train])
            X_test = face[test][:, np.newaxis]
            scores[ii] = rf.score(X_test, Y[test]) # スコアを保存
            coefs2 = np.zeros((n_splits, n_channels, n_delays-1))
            coefs2[ii] = rf.coef_[:, 0, :]  # モデルの係数を保存
        times = np.linspace(tmin, tmax, n_delays-1) # 遅延のタイミングを計算。np.linspace()は、指定された範囲内で等間隔の数値を生成

        # 交差検証スプリットごとのスコアと係数を平均化 coefは係数、scoreは相関係数
        mean_coefs = coefs2.mean(axis=0)
        mean_scores = scores.mean(axis=0)

        # 各遅延時間に対する処理を行う
        positive_sums = []
        positive_counts = []

        # mean_coefs のデータを元に処理を行う
        # mean_coefs が 32x65 の2次元配列として与えられていると仮定
        # 各遅延時間に対してループを行います
        for i in range(mean_coefs.shape[1]):
            # 各遅延時間における正の値のみを抽出して合計します
            positive_sum = np.sum(mean_coefs[:, i][mean_coefs[:, i] > 0])
            positive_sums.append(positive_sum)
            # 各遅延時間における正の値の個数を数えます
            positive_count = np.sum(mean_coefs[:, i] > 0)
            positive_counts.append(positive_count)
        # 正の値の平均を計算します
        positive_means = [positive_sum / positive_count if positive_count > 0 else 0 for positive_sum, positive_count in zip(positive_sums, positive_counts)]
        # 最も正の平均値が大きい遅延時間を見つけます
        max_positive_mean_index = np.argmax(positive_means)
        max_positive_mean_delay = times[max_positive_mean_index]
        #max_positive_mean_delay = 0.28
        # 結果を出力します
        print("Delay time with maximum positive mean:", max_positive_mean_delay)


        # 平均予測スコアをプロット
        #fig, ax = plt.subplots() # 新しい図と軸を作成
        ix_chs = np.arange(n_channels) # チャンネルのインデックスを作成
        #ax.plot(ix_chs, mean_scores) # 平均予測スコアをプロット
        #ax.set(title="Mean prediction score", xlabel="Channel", ylabel="Score ($r$)")


        #ヒートマップ
        time_plot = max_positive_mean_delay  # 特定の時間をハイライト
        fig, ax = plt.subplots(figsize=(4, 8)) #  新しい図と軸を作成
        max_coef = mean_coefs.max()
        # 係数のヒートマップを描画
        ax.pcolormesh(
            times,
            ix_chs,
            mean_coefs,
            cmap="RdBu_r",
            vmin=-max_coef,
            vmax=max_coef,
            shading="gouraud",
        )
        ax.axvline(time_plot, ls="--", color="k", lw=2) # 特定の時間を縦線でハイライト

        # 軸のラベルとタイトルを設定し
        ax.set(
            xlabel="Delay (s)",
            ylabel="Channel",
            title="Mean Model\nCoefficients",
            xlim=times[[0, -1]],
            ylim=[len(ix_chs) - 1, 0],
            xticks=np.arange(tmin, tmax + 0.2, 0.2),
        )

        plt.setp(ax.get_xticklabels(), rotation=45)
        plt.tight_layout()
        plt.savefig(f"/Users/ami/PycharmProjects/UCSD_pycharm/UCSD/0306/heatmap_{movie_number}_{feature_number}.png")

        # topomap
        # 'times' 配列内で 'time_plot' に最も近い時間を探し、そのインデックスを 'ix_plot' に格納
        ix_plot = np.argmin(np.abs(time_plot - times))
        fig, ax = plt.subplots() # 新しい図と軸を作成
        # "biosemi32" テンプレートを使用して Montage オブジェクト 'easycap_montage' を作成
        easycap_montage = mne.channels.make_standard_montage("biosemi32")
        # チャンネル名、サンプリング周波数、チャンネルタイプを指定して空の 'info' オブジェクトを作成
        info = mne.create_info(ch_names=easycap_montage.ch_names, sfreq=128, ch_types='eeg')  # 変更　！
        info.set_montage(easycap_montage)

        # モデル係数のトポグラフィを描画
        mne.viz.plot_topomap(mean_coefs[:, ix_plot], pos=info, axes=ax, show=False, vlim=(-max_coef, max_coef))
        ax.set(title="Topomap of model coefficients\nfor delay %s" % ix_plot)
        plt.tight_layout()
        plt.savefig(f"/Users/ami/PycharmProjects/UCSD_pycharm/UCSD/0306/topomap_{movie_number}_{feature_number}.png")

```
</details>

<details><summary>movie 5の被験者平均のmap</summary>
   
修正前　　
   
   <img width="982" alt="スクリーンショット 2024-03-05 14 38 09" src="https://github.com/am-da/mTRF/assets/112613519/d612807b-9572-4938-bc35-f7dc8aa1ccea">

 <br> 



修正後 

<img width="828" alt="スクリーンショット 2024-03-05 14 38 34" src="https://github.com/am-da/mTRF/assets/112613519/14bb18f8-bc4b-422c-956b-500a7ecf72ff">
</details>

 <br> 
 
### 脳波データ
'Fp1', 'AF3', 'F7', 'F3', 'FC1', 'FC5', 'T7', 'C3', 'CP1', 'CP5', 'P7', 'P3', 'Pz', 'PO3', 'O1', 'Oz', 'O2', 'PO4', 'P4', 'P8', 'CP6', 'CP2', 'C4', 'T8', 'FC6', 'FC2', 'F4', 'F8', 'AF4', 'Fp2', 'Fz', 'Cz'

<details><summary>subject 1</summary>

### memo
CP2, C4, FC2, Czがノイズあり？！

### movie 1  
<img width="1000" alt="スクリーンショット 2024-03-05 13 37 36" src="https://github.com/am-da/mTRF/assets/112613519/e03c342c-abda-4ec1-b6ff-c4bcf727c3bf">
 <br> 

### movie 3
<img width="1000" alt="スクリーンショット 2024-03-05 13 59 35" src="https://github.com/am-da/mTRF/assets/112613519/eb143e39-3435-4751-868b-5c84322cb568">
 <br> 

### movie 4  
<img width="1000" alt="スクリーンショット 2024-03-05 13 43 20" src="https://github.com/am-da/mTRF/assets/112613519/e575248c-a096-4fe0-a96d-e8b5e067a23d">
<img width="1000" alt="スクリーンショット 2024-03-05 13 56 35" src="https://github.com/am-da/mTRF/assets/112613519/424818f6-5326-4647-b387-af2741b52aca">
 <br> 

### movie 5  
<img width="1000" alt="スクリーンショット 2024-03-05 13 54 46" src="https://github.com/am-da/mTRF/assets/112613519/ecf810dd-48d0-47d9-8ff8-2a8972321531">
 <br> 

### movie 9
<img width="1066" alt="スクリーンショット 2024-03-06 4 33 16" src="https://github.com/am-da/mTRF/assets/112613519/b2ee54d9-a1df-400e-9118-46aaa920d405">
 <br> 

### movie 10
若干ノイズあり？
<img width="1080" alt="スクリーンショット 2024-03-06 4 36 35" src="https://github.com/am-da/mTRF/assets/112613519/a363a75f-a686-4e02-8188-81efd4a5f4fc">
 <br> 

### movie 17
 <img width="1070" alt="スクリーンショット 2024-03-06 4 44 10" src="https://github.com/am-da/mTRF/assets/112613519/a58638f1-b685-44a2-a632-0205236b35a9">
 <br> 

### movie 19
<img width="1087" alt="スクリーンショット 2024-03-06 4 47 04" src="https://github.com/am-da/mTRF/assets/112613519/c1bd7b3f-5dd4-4768-b10c-4fb48c0cc900">
<img width="1074" alt="スクリーンショット 2024-03-06 4 47 32" src="https://github.com/am-da/mTRF/assets/112613519/00fc83a3-8ab5-4e8e-9802-2560b8496c20">
 <br> 
 
### movie 20
<img width="1085" alt="スクリーンショット 2024-03-06 4 49 13" src="https://github.com/am-da/mTRF/assets/112613519/906df10b-32a0-427e-8c7e-d46d15fa4697">
 <br> 

### movie 21
<img width="1068" alt="スクリーンショット 2024-03-06 4 50 24" src="https://github.com/am-da/mTRF/assets/112613519/fd9c32d0-1d02-4ea9-9840-3607a52e38a1">
<img width="1074" alt="スクリーンショット 2024-03-06 4 51 07" src="https://github.com/am-da/mTRF/assets/112613519/7ad6c7dc-0a3c-4f0b-bc22-2436e6a4f72d">
 <br> 

### movie 22
<img width="1068" alt="スクリーンショット 2024-03-06 4 52 24" src="https://github.com/am-da/mTRF/assets/112613519/f96ca742-6bbe-42cc-9d31-e83e430594f6">
<img width="1058" alt="スクリーンショット 2024-03-06 4 52 49" src="https://github.com/am-da/mTRF/assets/112613519/12afa2b2-ac05-49ac-86b0-03d66dda4aae">

### movie 23
<img width="1071" alt="スクリーンショット 2024-03-06 4 54 07" src="https://github.com/am-da/mTRF/assets/112613519/e3649571-bd05-4138-9978-7572f007c435">

### movie 29
<img width="1077" alt="スクリーンショット 2024-03-06 4 59 50" src="https://github.com/am-da/mTRF/assets/112613519/96d9f4f3-be08-4171-a2bf-f6b1b21a4550">

</details>



<details><summary>subject 2</summary>

### memo
・Fp2とO1乱れがち  

・movie22以降、T7のノイズ

### movie 1
<img width="1197" alt="スクリーンショット 2024-03-06 12 46 03" src="https://github.com/am-da/mTRF/assets/112613519/53a8e790-d270-45ac-b10f-d45702addcbf">
<img width="1192" alt="スクリーンショット 2024-03-06 12 46 27" src="https://github.com/am-da/mTRF/assets/112613519/c8c559d9-7203-45eb-b12c-3b0cd1337d56">
<img width="1196" alt="スクリーンショット 2024-03-06 12 46 46" src="https://github.com/am-da/mTRF/assets/112613519/75aaa6b1-f7c9-4178-ac12-23ec7c464a7b">
 <br>  <br> 

### movie 2
<img width="1186" alt="スクリーンショット 2024-03-06 12 48 04" src="https://github.com/am-da/mTRF/assets/112613519/3fb8c471-3f00-4d16-96de-3a1cd66f48c1">
<img width="1198" alt="スクリーンショット 2024-03-06 12 48 27" src="https://github.com/am-da/mTRF/assets/112613519/45b203a7-b1ee-4a73-b4ad-44d539227679">
<img width="1194" alt="スクリーンショット 2024-03-06 12 48 40" src="https://github.com/am-da/mTRF/assets/112613519/feafca4c-6a79-45ef-a77c-b95da57c3cc1">
<img width="1185" alt="スクリーンショット 2024-03-06 12 48 54" src="https://github.com/am-da/mTRF/assets/112613519/5d5c3327-26a0-4b03-bd85-7ea3c8ce178e">
 <br>  <br> 


### movie 3
<img width="1071" alt="スクリーンショット 2024-03-06 12 51 17" src="https://github.com/am-da/mTRF/assets/112613519/50f0d5a6-f5df-49a1-94d6-ced0871e298c">
<img width="1058" alt="スクリーンショット 2024-03-06 12 51 49" src="https://github.com/am-da/mTRF/assets/112613519/a5d49766-be8b-4259-a1b4-14939395efc8">
<img width="1056" alt="スクリーンショット 2024-03-06 12 52 10" src="https://github.com/am-da/mTRF/assets/112613519/85730eb0-1334-4c75-80ac-489442a3499e">
<img width="1063" alt="スクリーンショット 2024-03-06 12 52 24" src="https://github.com/am-da/mTRF/assets/112613519/28e82a36-9051-48a2-890e-d39315dcfaa9">
 <br>  <br> 

### movie 11
 
O1のノイズ  

<img width="1077" alt="スクリーンショット 2024-03-06 12 53 34" src="https://github.com/am-da/mTRF/assets/112613519/ec1031b1-db5e-4398-b6da-890eaa6a09f2">
<img width="1050" alt="スクリーンショット 2024-03-06 12 53 59" src="https://github.com/am-da/mTRF/assets/112613519/602f7623-0780-4ba0-992c-f5df1b4fe7d2">
 <br>  <br> 

### movie 12

O1

 <img width="1050" alt="スクリーンショット 2024-03-06 12 55 57" src="https://github.com/am-da/mTRF/assets/112613519/539dc64a-05f1-47ae-b7b1-6c57eca4bd3c">
 <br>  <br> 

### movie 14

<img width="1271" alt="スクリーンショット 2024-03-06 12 58 45" src="https://github.com/am-da/mTRF/assets/112613519/18d81f9b-b560-4156-b34f-ae21b8eb807a">
 <br>  <br> 

### movie 22

T7のノイズ

<img width="1277" alt="スクリーンショット 2024-03-06 13 02 14" src="https://github.com/am-da/mTRF/assets/112613519/744b6453-cca2-48d9-9f01-5b60d18937df">
 <br>  <br> 

### movie 23
<img width="1287" alt="スクリーンショット 2024-03-06 13 03 49" src="https://github.com/am-da/mTRF/assets/112613519/a01ffa02-70db-4784-9507-bacfef5bfb68">
 <br>  <br> 
 
### movie 24
<img width="1292" alt="スクリーンショット 2024-03-06 13 05 56" src="https://github.com/am-da/mTRF/assets/112613519/1f8e09d8-6df6-4afd-877c-4f94104bd3bf">
 <br>  <br> 

### movie 25
 <img width="1274" alt="スクリーンショット 2024-03-06 13 07 09" src="https://github.com/am-da/mTRF/assets/112613519/56a61e9b-232b-47b2-a3c1-052ea4c370d2">
 <br>  <br> 
 
### movie 26
<img width="1290" alt="スクリーンショット 2024-03-06 13 08 44" src="https://github.com/am-da/mTRF/assets/112613519/6a63321e-7607-4ee6-b2e3-fd788f5e103e">
 <br>  <br> 

### movie 31
<img width="1285" alt="スクリーンショット 2024-03-06 13 10 00" src="https://github.com/am-da/mTRF/assets/112613519/63f8edda-f1a2-40d5-b622-9cf9ce268a48">
<img width="1288" alt="スクリーンショット 2024-03-06 13 09 49" src="https://github.com/am-da/mTRF/assets/112613519/70bb6276-67d3-40bd-b493-72084acad8cc">
 <br>  <br> 

 ### movie 32
 <img width="1280" alt="スクリーンショット 2024-03-06 13 11 15" src="https://github.com/am-da/mTRF/assets/112613519/058aee22-c62e-4fa1-9ad1-b8ec7a0ed892">
 <br>  <br> 
</details>



<details><summary>subject 3</summary>

### memo
・全体的に綺麗  

・movie22, 23, 24でCP2,CP2,FC2, FC2, Czのノイズ

### movie 1
<img width="1273" alt="スクリーンショット 2024-03-06 13 14 27" src="https://github.com/am-da/mTRF/assets/112613519/43d03dca-cc85-42f5-88a0-d822f9893431">
 <br>  <br> 
 
### movie 2
<img width="1286" alt="スクリーンショット 2024-03-06 13 15 34" src="https://github.com/am-da/mTRF/assets/112613519/fb504eb4-8654-4baa-bca5-270dbc93deee">
<img width="1288" alt="スクリーンショット 2024-03-06 13 16 06" src="https://github.com/am-da/mTRF/assets/112613519/5565d95c-65bb-4d43-beb2-0430672a7392">
 <br>  <br> 

### movie 3
<img width="1292" alt="スクリーンショット 2024-03-06 13 17 45" src="https://github.com/am-da/mTRF/assets/112613519/a45b34e8-571b-4d0c-ba55-378bfc6c7766">
 <br>  <br> 

### movie 22
<img width="1270" alt="スクリーンショット 2024-03-06 13 34 13" src="https://github.com/am-da/mTRF/assets/112613519/3baeff25-b252-4177-b635-c79b741e818e">
 <br>  <br> 

### movie 32
<img width="1271" alt="スクリーンショット 2024-03-06 13 40 08" src="https://github.com/am-da/mTRF/assets/112613519/16a1ec9a-99cc-416e-89f1-33e9b87deb1d">
</details>


<details><summary>subject 4</summary>

### memo
・Fp1, AF3のノイズ


### movie 1

<img width="1215" alt="スクリーンショット 2024-03-06 16 16 07" src="https://github.com/am-da/mTRF/assets/112613519/7508c010-3851-4fca-83e0-4a0ec5c55dc4">
<img width="1282" alt="スクリーンショット 2024-03-06 16 27 02" src="https://github.com/am-da/mTRF/assets/112613519/f1bcdb12-ad49-4e08-b875-893a8e80bdbc">
 <br>  <br> 

### movie 2
<img width="1269" alt="スクリーンショット 2024-03-06 16 40 35" src="https://github.com/am-da/mTRF/assets/112613519/94c080c4-bd76-40d7-96e1-a757f3378755">
 <br>  <br> 
 
### movie 3
<img width="1285" alt="スクリーンショット 2024-03-06 16 41 23" src="https://github.com/am-da/mTRF/assets/112613519/e1f4e6b5-a939-4bf9-98c0-520df35082f6">
<img width="1244" alt="スクリーンショット 2024-03-06 16 42 07" src="https://github.com/am-da/mTRF/assets/112613519/0e1744db-4aac-41de-bbed-f49966a0fe7b">
 <br>  <br> 

 ### movie 11
 T8, AF4, FP2
 
 <img width="1279" alt="スクリーンショット 2024-03-06 16 43 55" src="https://github.com/am-da/mTRF/assets/112613519/dc0dcb9e-e1eb-46a3-8a5b-0882e7da5d7d">
 <br>  <br> 

### movie 12
全体的にノイズ

<img width="1281" alt="スクリーンショット 2024-03-06 16 45 26" src="https://github.com/am-da/mTRF/assets/112613519/043bdef3-a8e0-41d1-86b9-68508a67d117">
<img width="1296" alt="スクリーンショット 2024-03-06 16 45 59" src="https://github.com/am-da/mTRF/assets/112613519/f17402e7-97b4-4167-9eef-5513884e1223">
 <br>  <br> 

### movie 13

<img width="1286" alt="スクリーンショット 2024-03-06 16 47 23" src="https://github.com/am-da/mTRF/assets/112613519/95569995-ea91-4d98-b84f-a7621bab46d6">
<img width="1278" alt="スクリーンショット 2024-03-06 16 47 05" src="https://github.com/am-da/mTRF/assets/112613519/9c6a1fe0-bda9-410c-9e6a-83dcd75413f4">
 <br>  <br> 

### movie 14
・Fp1, AF3

### movie 15 ⭐️
<img width="1302" alt="スクリーンショット 2024-03-06 16 49 19" src="https://github.com/am-da/mTRF/assets/112613519/8e1251e7-336b-4cbd-9161-3730f124ee3e">
<img width="1301" alt="スクリーンショット 2024-03-06 16 49 59" src="https://github.com/am-da/mTRF/assets/112613519/a053883a-f084-4444-ba24-037940cd82cf">
 <br>  <br> 

### movie 16 
<img width="1281" alt="スクリーンショット 2024-03-06 16 51 01" src="https://github.com/am-da/mTRF/assets/112613519/c6c71639-3a31-4e3f-b6e4-c7b3c15e23cf">
 <br>  <br> 
 
### movie 22
<img width="1308" alt="スクリーンショット 2024-03-06 16 52 19" src="https://github.com/am-da/mTRF/assets/112613519/851e9379-8083-4e7e-be07-91dca75c22e6">
 <br>  <br> 

### movie 23
<img width="1312" alt="スクリーンショット 2024-03-06 16 53 41" src="https://github.com/am-da/mTRF/assets/112613519/182fa524-c964-47d6-b3e8-2500fc1ad35d">

### movie 24 ⭐️

<img width="1282" alt="スクリーンショット 2024-03-06 16 54 39" src="https://github.com/am-da/mTRF/assets/112613519/82c7f2ba-6b2e-4f89-86e4-5fe4923d500f">
<img width="1279" alt="スクリーンショット 2024-03-06 16 55 01" src="https://github.com/am-da/mTRF/assets/112613519/b9e39e10-8542-4f8f-a7fe-aaa5d8105d6b">
<img width="1278" alt="スクリーンショット 2024-03-06 16 55 16" src="https://github.com/am-da/mTRF/assets/112613519/731d471a-8312-472d-a25a-4abb037affd4">
</details>

 <br> 

## 被験者平均

<details><summary>time_plot</summary>

### time_plotの決め方を迷う
１. 係数の正の値の平均値が最大のものを選択
2. 係数が正であるものの数が最大のものを選択

### 1
<img width="700" alt="スクリーンショット 2024-03-06 22 20 20" src="https://github.com/am-da/mTRF/assets/112613519/9689dee2-2bac-42cf-9f15-5e58e09eb2aa">
 <br> 

### 2
<img width="697" alt="スクリーンショット 2024-03-06 22 11 13" src="https://github.com/am-da/mTRF/assets/112613519/92a51b4d-f942-4656-9ae9-8388590d4ab7">
</details>

⭐️score : スコアは、モデルが予測した脳波と実際の脳波の類似度を示す。相関係数が1に近いほど、モデルの予測が実際のデータに良く適合していることを意味する。  

<img width="700" alt="スクリーンショット 2024-03-06 22 28 59" src="https://github.com/am-da/mTRF/assets/112613519/ce46b922-813a-4824-acdb-b071f68cf434">
 <br>   <br> 
 
 
・coefは係数 (モデルが予測を行う際に各遅延がどれだけの重要性を持つかを示す )  
・coefsの形状は(n_splits, n_channels, n_delays)  
・scoresは相関係数 (各分割でのモデルの評価スコアを保存)  
・scoresの形状は(n_splits, n_channels)  



<details><summary> feature 1 - movie 1 ~ 15 </summary>

<details><summary> 自動 </summary>
<img width="1304" alt="スクリーンショット 2024-03-07 13 25 58" src="https://github.com/am-da/mTRF/assets/112613519/9296327f-88cf-425e-8a1b-2b41833a03e7">
</details>

### movie 1
<img width="876" alt="スクリーンショット 2024-03-07 13 51 49" src="https://github.com/am-da/mTRF/assets/112613519/668ab10c-ad38-4cfb-beaf-2865e1158c6f">

### movie 2
<img width="858" alt="スクリーンショット 2024-03-07 13 52 14" src="https://github.com/am-da/mTRF/assets/112613519/7fe78c10-0d6e-470a-a212-d5b2e3a8173b">

### movie 3


</details>




## ジャンル分け

<details><summary>movieのジャンル</summary>
  
last fmの感情タグを反映。それ以外は空白。  

| subject | last.fm tag |
|:---:|:---:|
| 1 | fun |
| 2 | exciting |
| 3 | joy |
| 11 | happy |
| 12 | cheerful |
| 13 | love |
| 14 | happy |
| 15 | lovely |
| 16 | sentimental |
| 22 | sentimental |
| 23 | melancholy |
| 24 | sad |
| 25 | depressing |
| 26 | mellow |
| 31 | terrible |
| 32 | shock |
| 33 | hate |

</details>










