

## 1. 32以降のchannel

<br> 

<img width="750" alt="スクリーンショット 2024-03-12 13 35 48" src="https://github.com/am-da/mTRF/assets/112613519/a1be7172-fe25-47b4-a52d-609c6f7ab722">

<br> 



## 2. ICA

参考

https://www.nmr.mgh.harvard.edu/mne/0.14/auto_tutorials/plot_ica_from_raw.html


<details><summary>EOGを除く (3/22)</summary>

・find_bads_eog  
https://mne.tools/stable/generated/mne.preprocessing.ICA.html#mne.preprocessing.ICA.find_bads_eog

・mne.preprocessing.create_eog_epochs  
https://mne.tools/dev/generated/mne.preprocessing.create_eog_epochs.html

<img width="895" alt="スクリーンショット 2024-03-22 8 39 22" src="https://github.com/am-da/mTRF/assets/112613519/c096f872-975e-4c7b-82cf-c7136cb7e130">

<img width="965" alt="スクリーンショット 2024-03-22 8 39 00" src="https://github.com/am-da/mTRF/assets/112613519/393d3253-2e0e-4fac-95dd-70eed7f1e8d9">

<br>

<img width="637" alt="スクリーンショット 2024-03-22 8 44 34" src="https://github.com/am-da/mTRF/assets/112613519/24c9f553-1adc-4c71-a90c-085f5fa51d46">


<details><summary>コード</summary>

```Python
import mne
from mne.preprocessing import create_eog_epochs

raw = mne.io.read_raw_bdf('/Users/ami/PycharmProjects/UCSD_pycharm/UCSD/DEAP_data/data_original/s01.bdf', preload=True)
# EOGチャンネル名を変更する
#raw.rename_channels(mapping={'EXG3': 'vEOG1', 'EXG4': 'vEOG2'})
# 脳波のチャンネルのインデックスを指定
brain_channels = list(range(0, 32))

# 脳波のチャンネルのみを選択してデータを作成
raw_brain = raw.copy().pick_channels([raw.ch_names[i] for i in brain_channels])
raw_brain.set_montage("biosemi32")
print(raw_brain.ch_names)

# デジタルフィルタリング
raw_brain.filter(1, 50, fir_design='firwin')

# ダウンサンプリング（128Hzにダウンサンプリング）
raw_brain.resample(128)

# 平均リファレンスを適用
raw_brain.set_eeg_reference('average', projection=True)
raw_brain.apply_proj()

print("ch_names[34]",raw.ch_names[34]) #vEOG1
print("ch_names[35]",raw.ch_names[35]) #vEOG2
print("raw._data[34]" ,raw._data[34])
raw._data[34]= abs(raw.get_data(34) - raw.get_data(35))
print("raw._data[34]" ,raw._data[34])

# ICA
# set up and fit the ICA
reject=dict(mag=4e-12, grad=4000e-13)
ica = mne.preprocessing.ICA(n_components= 25, random_state = 23, method='fastica')

picks_eeg = mne.pick_types(raw_brain.info, eeg = True)
ica.fit(raw_brain, picks = picks_eeg, reject=reject)
print("ica",ica)

ica.plot_components()

#eog_epochs = create_eog_epochs(raw, ch_name= ['EXG1'])
#print("eog_epochs",eog_epochs)

brain_channels = list(range(0, 32)) + [34]
raw_brain_eog = raw.copy().pick_channels([raw.ch_names[i] for i in brain_channels])

print(raw.get_data(picks='EXG3'))
eog_index,scores=ica.find_bads_eog(raw_brain_eog, ch_name= ['EXG3'])

print("eog_index",eog_index)
print("scores",scores)
ica.plot_scores(scores)

```
</details>
</details>


### 疑問
・raw_brain.set_montage("biosemi32")があるため、raw_brainには32チャンネル分しか読み込めない  

・ica.fitにはraw_brainを用いている  
ica.fit(raw_brain, picks = picks_eeg, reject=reject)  

・ica.find_bads_eogでは35番目のチャンネルを用いたいが、それはraw_brainには含まれないため、rawを用いている  
eog_index,scores=ica.find_bads_eog(raw, ch_name= ['EXG3'])  


<details><summary> 1 epochsあり  (3/28)</summary>


<img width="937" alt="スクリーンショット 2024-03-28 11 23 22" src="https://github.com/am-da/mTRF/assets/112613519/bb8d6f1f-9c58-45a7-aabb-e2b454f303a3">
<img width="965" alt="スクリーンショット 2024-03-28 11 23 33" src="https://github.com/am-da/mTRF/assets/112613519/7a63d1d3-9580-46e2-b680-dcf7a022659c">
<img width="847" alt="スクリーンショット 2024-03-28 11 23 57" src="https://github.com/am-da/mTRF/assets/112613519/6fe4b787-3853-45f0-b9ec-d890964eaedf">


<details><summary>コード</summary>
  
```Python
import mne
from mne.preprocessing import create_eog_epochs

raw = mne.io.read_raw_bdf('/Users/ami/PycharmProjects/UCSD_pycharm/UCSD/DEAP_data/data_original/s01.bdf', preload=True)
# 脳波のチャンネルのインデックスを指定
brain_channels = list(range(0, 32))

# 脳波のチャンネルのみを選択してデータを作成
raw_brain = raw.copy().pick_channels([raw.ch_names[i] for i in brain_channels])
print(raw_brain.ch_names)
raw_brain.set_montage("biosemi32")

# デジタルフィルタリング
raw_brain.filter(1, 50, fir_design='firwin')

# ダウンサンプリング（128Hzにダウンサンプリング）
raw_brain.resample(128)

# 平均リファレンスを適用
raw_brain.set_eeg_reference('average', projection=True)
raw_brain.apply_proj()


print("ch_names[34]",raw.ch_names[34]) #vEOG1 = EXG3
print("ch_names[35]",raw.ch_names[35]) #vEOG2 = EXG4
print("raw._data[34]" ,raw._data[34])
raw._data[34]= abs(raw.get_data(34) - raw.get_data(35))
print("raw._data[34]" ,raw._data[34])


# ICA
# set up and fit the ICA
reject=dict(mag=4e-12, grad=4000e-13)
ica = mne.preprocessing.ICA(n_components= 25, random_state = 23, method='fastica')

picks_eeg = mne.pick_types(raw_brain.info, eeg = True)
ica.fit(raw_brain, picks = picks_eeg, reject=reject)
#ica.exclude = [0]
print("ica",ica)

ica.plot_components()

eog_epochs = create_eog_epochs(raw, ch_name= ['EXG3'])

# eog_epochsだけでいけると思ったら、EOGチャンネルを指定しないとダメだった
eog_index,scores=ica.find_bads_eog(eog_epochs, ch_name= ['EXG3'])

print("eog_index",eog_index)
print("scores",scores)
ica.plot_scores(scores)
```

</details>

</details>


<details><summary> 2 epochsなし　</summary>
<img width="730" alt="スクリーンショット 2024-03-28 11 27 49" src="https://github.com/am-da/mTRF/assets/112613519/2bde00d5-fc56-4baf-b603-7e4bd43b08db">
</details>


<details><summary> 3 vEOG1のみ　</summary>
<img width="642" alt="スクリーンショット 2024-03-28 16 25 03" src="https://github.com/am-da/mTRF/assets/112613519/b7650bbb-b7a6-48fc-9443-361a60b9ffaf">
</details>

<details><summary> 4 vEOG2のみ　</summary>
<img width="637" alt="スクリーンショット 2024-03-28 16 27 56" src="https://github.com/am-da/mTRF/assets/112613519/a801052c-71bb-459c-af39-cbedc12e723f">
</details>

<details><summary> 5 hEOG1のみ　</summary>
<img width="641" alt="スクリーンショット 2024-03-28 16 30 14" src="https://github.com/am-da/mTRF/assets/112613519/cca4337c-4c28-4fef-9763-9d61625b1493">
</details>

<br> 





## 3. 補間

<br> 

http://meg.aalip.jp/python/MNE2-tutorial-noise.html

<img width="700" alt="スクリーンショット 2024-03-22 8 27 14" src="https://github.com/am-da/mTRF/assets/112613519/25e5797c-ff6a-4b57-9e27-fd2320a2f079">

http://meg.aalip.jp/python/MNE_tutorial_rejecting.htm

<br> 

https://mne.tools/stable/generated/mne.read_evokeds.html

<br> 

<img width="700" alt="スクリーンショット 2024-03-22 8 30 26" src="https://github.com/am-da/mTRF/assets/112613519/8b30fd2b-d7c9-492c-a03a-052874b7b7e2">


<br> 

<details><summary>コード</summary>

```Python
import mne

movie_number = range(1, 2) # 動画の番号 (1~40)
feature_number = range(1, 2) # 特徴量17
subject_number = 1 # 被験者数22人

eeg_path = f"/Users/ami/PycharmProjects/UCSD_pycharm/UCSD/prepro_{subject_number:02d}.fif"
raw = mne.io.read_raw_fif(eeg_path, preload=True) #EEGデータの読み込み

# チャンネル1〜32のデータを合計
data = raw.get_data(picks=list(range(0, 32)))

#average_data = data.mean(axis=0)
#print(average_data.shape)
#average_data = average_data.reshape(1, -1)
#print(average_data.shape)

info = mne.create_info(raw.ch_names, sfreq = 128)
# 条件を指定して新しい Evoked データを作成する
evoked_new = mne.EvokedArray(data, info, tmin=raw.times[0], comment='Left Auditory')

# 作成した Evoked データをファイルに保存する
save_path_new = "/Users/ami/PycharmProjects/UCSD_pycharm/UCSD/eeg_ave.fif"
evoked_new.save(save_path_new, overwrite=True)

# 保存されたファイルを再度読み込んでデータを確認する
#evoked_loaded = mne.read_evokeds(save_path_new, condition='Left Auditory', baseline=(0, 0))
#print(evoked_loaded)

raw.info['bads']=['F7']
#特定の条件（"Left Auditory"）の脳波の平均応答
evoked=mne.read_evokeds(save_path_new,condition='Left Auditory',baseline=(0,0))
#チャンネルの選択
evoked.pick_types(exclude=[])
#選択された脳波の平均応答をプロット
evoked.plot(exclude=[])
print(evoked.info["bads"])

evoked.plot(exclude=[])
print(evoked.info["bads"])
```
</details>

<br> 



## 4. ASR (Artifact Subspace Reconstruction)

MNE用のASRはまだない
https://mne.discourse.group/t/asr-in-python-for-eeg/6295

