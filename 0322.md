

### 1. 32以降のchannel

<br> 

<img width="900" alt="スクリーンショット 2024-03-12 13 35 48" src="https://github.com/am-da/mTRF/assets/112613519/a1be7172-fe25-47b4-a52d-609c6f7ab722">

<br> 



## ICA

### EOGを除く

・find_bads_eog
https://mne.tools/stable/generated/mne.preprocessing.ICA.html#mne.preprocessing.ICA.find_bads_eog

・mne.preprocessing.create_eog_epochs
https://mne.tools/dev/generated/mne.preprocessing.create_eog_epochs.html

<img width="911" alt="スクリーンショット 2024-03-21 17 52 17" src="https://github.com/am-da/mTRF/assets/112613519/329405fb-64c9-4d57-b108-fe4d204d8b46">
<img width="967" alt="スクリーンショット 2024-03-21 17 52 28" src="https://github.com/am-da/mTRF/assets/112613519/ffdbc23d-213e-45a7-a275-434197970702">
<img width="780" alt="スクリーンショット 2024-03-21 17 52 59" src="https://github.com/am-da/mTRF/assets/112613519/a3df2754-98ba-4c58-a5b8-9fe7188f58cb">

<details><summary>コード</summary>

```Python
import mne

raw = mne.io.read_raw_bdf('/Users/ami/PycharmProjects/UCSD_pycharm/UCSD/DEAP_data/data_original/s01.bdf', preload=True)
# EOGチャンネル名を変更する
#raw.rename_channels(mapping={'EXG3': 'vEOG1', 'EXG4': 'vEOG2'})
# 脳波のチャンネルのインデックスを指定
brain_channels = list(range(0, 32))

# 脳波のチャンネルのみを選択してデータを作成
raw_brain = raw.copy().pick_channels([raw.ch_names[i] for i in brain_channels])
raw_brain.set_montage("biosemi32")
print(raw_brain.ch_names)

# デジタルフィルタリング
raw_brain.filter(1, 50, fir_design='firwin')

# ダウンサンプリング（128Hzにダウンサンプリング）
raw_brain.resample(128)

# 平均リファレンスを適用
raw_brain.set_eeg_reference('average', projection=True)
raw_brain.apply_proj()

print("ch_names[34]",raw.ch_names[34]) #vEOG1
print("ch_names[35]",raw.ch_names[35]) #vEOG2
print("raw._data[34]" ,raw._data[34])
raw._data[34]= abs(raw.get_data(34) - raw.get_data(35))
print("raw._data[34]" ,raw._data[34])

# ICA
# set up and fit the ICA
reject=dict(mag=4e-12, grad=4000e-13)
ica = mne.preprocessing.ICA(n_components= 25, random_state = 23, method='fastica')

picks_eeg = mne.pick_types(raw_brain.info, eeg = True)
ica.fit(raw_brain, picks = picks_eeg, reject=reject)
print("ica",ica)

ica.plot_components()

#eog_epochs = create_eog_epochs(raw, ch_name= ['EXG1'])
#print("eog_epochs",eog_epochs)

brain_channels = list(range(0, 32)) + [34]
raw_brain_eog = raw.copy().pick_channels([raw.ch_names[i] for i in brain_channels])

eog_index,scores=ica.find_bads_eog(raw_brain_eog, ch_name= ['EXG3'])

print("eog_index",eog_index)
print("scores",scores)
ica.plot_scores(scores)
```
</details>

<br> 


### 補間

http://meg.aalip.jp/python/MNE2-tutorial-noise.html
<img width="833" alt="スクリーンショット 2024-03-22 8 27 14" src="https://github.com/am-da/mTRF/assets/112613519/25e5797c-ff6a-4b57-9e27-fd2320a2f079">

http://meg.aalip.jp/python/MNE_tutorial_rejecting.htm


<details><summary>コード</summary>

```Python
import mne

movie_number = range(1, 2) # 動画の番号 (1~40)
feature_number = range(1, 2) # 特徴量17
subject_number = 1 # 被験者数22人

eeg_path = f"/Users/ami/PycharmProjects/UCSD_pycharm/UCSD/prepro_{subject_number:02d}.fif"
raw = mne.io.read_raw_fif(eeg_path, preload=True) #EEGデータの読み込み

# チャンネル1〜32のデータを合計
data = raw.get_data(picks=list(range(0, 32)))

#average_data = data.mean(axis=0)
#print(average_data.shape)
#average_data = average_data.reshape(1, -1)
#print(average_data.shape)

info = mne.create_info(raw.ch_names, sfreq = 128)
# 条件を指定して新しい Evoked データを作成する
evoked_new = mne.EvokedArray(data, info, tmin=raw.times[0], comment='Left Auditory')

# 作成した Evoked データをファイルに保存する
save_path_new = "/Users/ami/PycharmProjects/UCSD_pycharm/UCSD/eeg_ave.fif"
evoked_new.save(save_path_new, overwrite=True)

# 保存されたファイルを再度読み込んでデータを確認する
#evoked_loaded = mne.read_evokeds(save_path_new, condition='Left Auditory', baseline=(0, 0))
#print(evoked_loaded)

raw.info['bads']=['F7']
evoked=mne.read_evokeds(save_path_new,condition='Left Auditory',baseline=(0,0))
evoked.pick_types(exclude=[])
evoked.plot(exclude=[])
print(evoked.info["bads"])

evoked.plot(exclude=[])
print(evoked.info["bads"])
```
</details>

<br> 


### ASR

MNE用のASRはまだない
https://mne.discourse.group/t/asr-in-python-for-eeg/6295

