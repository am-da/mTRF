
### 1. ダウンサンプリング (128 → 256)

元々のサンプリングは512 Hz


・resample(128)  

<img width="600" alt="スクリーンショット 2024-04-04 17 27 37" src="https://github.com/am-da/mTRF/assets/112613519/2cb954d0-bede-4b57-a38c-c5f25998a2af">

・resample(256)  

<img width="600" alt="スクリーンショット 2024-04-04 17 24 49" src="https://github.com/am-da/mTRF/assets/112613519/dae792d8-f33a-44ef-a5a9-bbdac805f1dc">

<br> 

<br> 

### 2. notch filter

subject 4 - movie 33    

Twente(オランダ)は 電源周波数50Hz   


・notch filter なし  
<img width="600" alt="スクリーンショット 2024-04-05 3 39 22" src="https://github.com/am-da/mTRF/assets/112613519/024bd14f-cfca-4f99-b260-b7aa6fb7a43e">

<br> 

・notch filter あり  
<img width="600" alt="スクリーンショット 2024-04-05 3 40 03" src="https://github.com/am-da/mTRF/assets/112613519/237d1889-85b6-40a3-8bda-89b508f38418">

<br> 

<details><summary>コード</summary>  
  
```python
import mne
import numpy as np

# 変更
raw = mne.io.read_raw_bdf('/Users/ami/PycharmProjects/UCSD_pycharm/UCSD/DEAP_data/data_original/s04.bdf', preload=True)

# 脳波のチャンネルのインデックスを指定
brain_channels = list(range(0, 32))

# 脳波のチャンネルのみを選択してデータを作成
raw_brain = raw.copy().pick_channels([raw.ch_names[i] for i in brain_channels])
print(raw_brain.ch_names)

# notch
raw_brain.notch_filter(np.arange(50, 251, 50),filter_length='auto')

# デジタルフィルタリング
raw_brain.filter(1, 50, fir_design='firwin')

# ダウンサンプリング（256Hzにダウンサンプリング）
raw_brain.resample(256)

# 平均リファレンスを適用
raw_brain.set_eeg_reference('average', projection=True)
raw_brain.apply_proj()

# 変更
start_time = 2654.794922
end_time = start_time + 60

raw_brain.crop(tmin=start_time, tmax=end_time)  # 指定した時間帯のデータを抽出
raw_brain.plot()

```

</details>


<details><summary>参考</summary>  
https://mne.tools/stable/generated/mne.io.Raw.html#mne.io.Raw.notch_filter
<img width="793" alt="スクリーンショット 2024-04-04 23 51 59" src="https://github.com/am-da/mTRF/assets/112613519/df9d46cb-5e37-411f-8e47-63c41bc8635f">
</details>

<br> 



### 3. アーチファクト検知 (MNE-Python)

subject 4

notch filter 処理前  

<img width="800" alt="スクリーンショット 2024-04-05 4 27 42" src="https://github.com/am-da/mTRF/assets/112613519/1a169b07-7dae-499e-b850-01cc42352e72">

<br> 

notch filter 処理後  

<img width="800" alt="スクリーンショット 2024-04-05 4 26 47" src="https://github.com/am-da/mTRF/assets/112613519/5eadccaf-991d-4c2d-9b1c-68d0de1d02ac">

<br> 


<img width="600" alt="スクリーンショット 2024-04-05 5 15 08" src="https://github.com/am-da/mTRF/assets/112613519/ce57db5b-c673-46c5-9a51-9f5a307d1d92">

<br> 


<details><summary>参考</summary>  
<img width="662" alt="スクリーンショット 2024-04-05 4 25 53" src="https://github.com/am-da/mTRF/assets/112613519/a5c86631-8e85-4862-ba28-271fc210dc9f">
https://mne.tools/dev/auto_tutorials/preprocessing/10_preprocessing_overview.html
</details>


<details><summary>コード</summary>  
  
```python
import mne
import numpy as np

# 変更
raw = mne.io.read_raw_bdf('/Users/ami/PycharmProjects/UCSD_pycharm/UCSD/DEAP_data/data_original/s04.bdf', preload=True)

# 脳波のチャンネルのインデックスを指定
brain_channels = list(range(0, 32))

# 脳波のチャンネルのみを選択してデータを作成
raw_brain = raw.copy().pick_channels([raw.ch_names[i] for i in brain_channels])
print(raw_brain.ch_names)

#raw_brain.notch_filter(np.arange(50, 251, 50), filter_length='auto')

# デジタルフィルタリング
raw_brain.filter(1, 50, fir_design='firwin')

# ダウンサンプリング
raw_brain.resample(256)

fig = raw_brain.compute_psd(tmax=np.inf, fmax=128).plot(
    average=True, amplitude=False, picks="data", exclude="bads"
)

```

</details>

<br> 


### 4. 脳波計について

https://www.eecs.qmul.ac.uk/mmv/datasets/deap/doc/tac_special_issue_2011.pdf

<img width="626" alt="スクリーンショット 2024-04-05 0 23 56" src="https://github.com/am-da/mTRF/assets/112613519/cd56bee0-3265-4bf8-b3bb-878583d52bd6">
<img width="740" alt="スクリーンショット 2024-04-05 0 24 34" src="https://github.com/am-da/mTRF/assets/112613519/0924918e-dfee-47b7-be2c-a9adc62da1d1">

脳波の特定の周波数帯域と脳波の関連(?)  

<br> 

https://www.eecs.qmul.ac.uk/mmv/datasets/deap/readme.html
<img width="1095" alt="スクリーンショット 2024-04-05 0 38 00" src="https://github.com/am-da/mTRF/assets/112613519/b7962aaa-b685-47af-91d4-96a756e9e427">

<br> 


## 5. funとsadの比較

movie 1 と movie 24　の比較


<details><summary>movieのジャンル分け</summary>
  
last fmの感情タグを反映。それ以外は空白。  

| movie | last.fm tag |
|:---:|:---:|
| 1 | fun |
| 2 | exciting |
| 3 | joy |
| 11 | happy |
| 12 | cheerful |
| 13 | love |
| 14 | happy |
| 15 | lovely |
| 16 | sentimental |
| 22 | sentimental |
| 23 | melancholy |
| 24 | sad |
| 25 | depressing |
| 26 | mellow |
| 31 | terrible |
| 32 | shock |
| 33 | hate |


</details>


<details><summary>movie 1　の被験者平均　（before noise reduction）</summary>
<img width="1036" alt="スクリーンショット 2024-04-05 3 46 15" src="https://github.com/am-da/mTRF/assets/112613519/9cc928bb-44f3-4761-8ca0-481476d9838b">
</details>

<details><summary>movie 24　の被験者平均　（before noise reduction）</summary>
<img width="1012" alt="スクリーンショット 2024-04-05 4 07 10" src="https://github.com/am-da/mTRF/assets/112613519/96d5358b-508f-41e9-aa62-356e8fb0a49e">
</details>


<details><summary>コード (notch & dresample まで)</summary>  
  
```python
subject_numbers = range(1, 23)
for subject_number in subject_numbers:
    raw = mne.io.read_raw_bdf(f'/Users/ami/PycharmProjects/UCSD_pycharm/UCSD/DEAP_data/data_original/s{subject_number:02d}.bdf',preload=True)
    brain_channels = list(range(0, 32))
    raw_brain = raw.copy().pick_channels([raw.ch_names[i] for i in brain_channels])
    print(raw_brain.ch_names)
    raw_brain.notch_filter(np.arange(50, 251, 50), filter_length='auto')
    raw_brain.filter(1, 50, fir_design='firwin')
    raw_brain.resample(256)
    output_path = f'/Users/ami/PycharmProjects/UCSD_pycharm/UCSD/new_0404_till_down/prepro_{subject_number:02d}.fif'
    raw_brain.save(output_path, overwrite=True)

```

</details>


<details><summary>movie 1　の被験者平均　（after noise reduction）</summary>  

</details>


<details><summary>movie 24　の被験者平均　（after noise reduction）</summary>

</details>

<br> 

### 6. movie 1 のデータ処理

<img width="600" alt="スクリーンショット 2024-04-05 7 05 32" src="https://github.com/am-da/mTRF/assets/112613519/b18ab7f9-ac3a-474d-ae42-5607827308eb">

<br> 

<br> 

subject 1 - moive 2  

<img width="700" alt="スクリーンショット 2024-04-05 7 09 51" src="https://github.com/am-da/mTRF/assets/112613519/32e91e80-3018-4cc3-bb62-7a6b73123e2d">

<br> 



### 7. ICA 

componentを３２に変更  

・subject 1 - EXG1(to the left of left eye)  

<img width="800" alt="スクリーンショット 2024-04-05 7 17 45" src="https://github.com/am-da/mTRF/assets/112613519/2fa7c131-7633-4589-ad6c-416bb43438e2">
<img width="800" alt="スクリーンショット 2024-04-05 7 17 57" src="https://github.com/am-da/mTRF/assets/112613519/9125803f-0a7d-4bff-a9d1-a1f383bdd4f8">
<img width="600" alt="スクリーンショット 2024-04-05 7 19 27" src="https://github.com/am-da/mTRF/assets/112613519/b1d7811a-12e8-46f8-a360-fd7d83043985">


<br> 

・subject 1 - EXG3(above right eye)  

<img width="890" alt="スクリーンショット 2024-04-05 7 26 55" src="https://github.com/am-da/mTRF/assets/112613519/fa06c647-6f3c-433e-b4c7-9c1dfefd1b13">
<img width="970" alt="スクリーンショット 2024-04-05 7 27 46" src="https://github.com/am-da/mTRF/assets/112613519/0dcaa5c0-b5c0-45b0-9c58-74e68116556c">
<img width="750" alt="スクリーンショット 2024-04-05 7 28 24" src="https://github.com/am-da/mTRF/assets/112613519/552e0d13-0813-4bc9-ab6e-03854f2c3e0d">



<details><summary>コード</summary>  
  
```python

import mne
from mne.preprocessing import create_eog_epochs

raw = mne.io.read_raw_bdf('/Users/ami/PycharmProjects/UCSD_pycharm/UCSD/DEAP_data/data_original/s01.bdf', preload=True)
# 脳波のチャンネルのインデックスを指定
brain_channels = list(range(0, 32))

# 脳波のチャンネルのみを選択してデータを作成
raw_brain = raw.copy().pick_channels([raw.ch_names[i] for i in brain_channels])
print(raw_brain.ch_names)
raw_brain.set_montage("biosemi32")

raw_brain.notch_filter(np.arange(50, 251, 50), filter_length='auto')

# デジタルフィルタリング
raw_brain.filter(1, 50, fir_design='firwin')

# ダウンサンプリング
raw_brain.resample(256)

# 平均リファレンスを適用
#raw_brain.set_eeg_reference('average', projection=True)
#raw_brain.apply_proj()

print("ch_names[34]",raw.ch_names[34]) #vEOG1 = EXG3
print("ch_names[35]",raw.ch_names[35]) #vEOG2 = EXG4
print("raw._data[34]" ,raw._data[34])
print("raw._data[34]" ,raw._data[34])

# ICA
# set up and fit the ICA
reject=dict(mag=4e-12, grad=4000e-13)
ica = mne.preprocessing.ICA(n_components= 32, random_state = 23, method='fastica')

picks_eeg = mne.pick_types(raw_brain.info, eeg = True)
ica.fit(raw_brain, picks = picks_eeg, reject=reject)
print("ica",ica)

ica.plot_components()

eog_index,scores=ica.find_bads_eog(raw, ch_name= ['EXG1'])

print("eog_index",eog_index)
print("scores",scores)
ica.plot_scores(scores)
```

</details>

<details><summary>参考</summary>  
<img width="624" alt="スクリーンショット 2024-04-05 7 31 17" src="https://github.com/am-da/mTRF/assets/112613519/5870eb8a-cac4-4b4e-86bc-7ef78086e1c7">
http://meg.aalip.jp/python/MNE_tutorial_ICA.htm
</details>


<br> 

<img width="750" alt="スクリーンショット 2024-03-12 13 35 48" src="https://github.com/am-da/mTRF/assets/112613519/a1be7172-fe25-47b4-a52d-609c6f7ab722">

<br> 





### 参考サイト

https://qiita.com/ponpopon_pon/items/32e931058841acc7dee5

https://qiita.com/sentencebird/items/035ba0c48569f06e3a42






